{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgla6aF_0ZcY",
        "outputId": "850d4feb-2902-4506-dfa2-b31ee068f247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wFr77uDdxTpq",
        "outputId": "42f1eb46-3756-4c92-fd45-c288cacfe90c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction to Tensors"
      ],
      "metadata": {
        "id": "yHd4sNz55tBk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CRk_DwkvWBPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Tensors --> Number representation of Data in deep learning.."
      ],
      "metadata": {
        "id": "rpNxFVfdKBNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalars - Single element:\n",
        "scalar = torch.tensor(10)\n",
        "scalar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO6jFx3tKK65",
        "outputId": "00275fb3-ba4b-4473-f567-c37bec3378e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Dimension of Tensor, turning Tensor into integer, shape of tensor\n",
        "scalar.ndim, scalar.item(), scalar.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBg-72bmLNpQ",
        "outputId": "a4cb3e33-b4ff-4175-c7e9-a29c16c28ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 10, torch.Size([]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector - single dimension tensor but can contain many numbers.\n",
        "vector = torch.tensor([10, 10, 10, 10])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7xybnLsKkOt",
        "outputId": "4cf4d6b7-5c4e-4b8f-d858-62d848bf6dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 10, 10, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.ndim, vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY71mRjXLw_-",
        "outputId": "c0ec9361-5ac9-4dc5-9ec3-3cfd52c29308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, torch.Size([4]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MATRIX - Tensors with 2 dimensions\n",
        "MATRIX = torch.tensor([\n",
        "    [10, 10, 5, 7],\n",
        "    [9, 9, 10, 100]\n",
        "])\n",
        "MATRIX, MATRIX.ndim, MATRIX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMyF9lpAK9fN",
        "outputId": "635df7e3-bd20-4354-ca29-7a7748929d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 10,  10,   5,   7],\n",
              "         [  9,   9,  10, 100]]),\n",
              " 2,\n",
              " torch.Size([2, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensors - Tensors with more dimensions, tensors can represent almost anything.\n",
        "TENSOR = torch.tensor([\n",
        "    [\n",
        "        [1,2,3,4],\n",
        "        [5,6,7,8],\n",
        "        [9,10,21,13],\n",
        "    ]\n",
        "])\n",
        "TENSOR, TENSOR.ndim, TENSOR.shape, TENSOR.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3G1MFbSK_hg",
        "outputId": "666d76d4-74d7-4d0d-b7e4-ab2fea722d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 1,  2,  3,  4],\n",
              "          [ 5,  6,  7,  8],\n",
              "          [ 9, 10, 21, 13]]]),\n",
              " 3,\n",
              " torch.Size([1, 3, 4]),\n",
              " torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Tensors\n",
        "# Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...\n",
        "\n",
        "rand_tensor = torch.rand(size=(2,4))\n",
        "rand_tensor, rand_tensor.shape, rand_tensor.ndim, rand_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4ax719kNkcg",
        "outputId": "44988c39-730b-4ff8-d30e-c5d87751e764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.7269, 0.9483, 0.4042, 0.7882],\n",
              "         [0.5208, 0.9275, 0.6327, 0.5597]]),\n",
              " torch.Size([2, 4]),\n",
              " 2,\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The flexibility of torch.rand() is that we can adjust the size to be whatever we want.\n",
        "#  EG: image shape of [224, 224, 3] ([height, width, color_channels]). (Also color channel comes first)\n",
        "\n",
        "\n",
        "# Create a random tensor for img of size (224, 224, 3)\n",
        "rand_tensor_img = torch.rand(size=(3, 224, 224))\n",
        "rand_tensor_img.shape, rand_tensor.ndim, rand_tensor_img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9swm628kWf4l",
        "outputId": "f2b66bc8-36c3-4676-ce22-94c8597511f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 224, 224]),\n",
              " 2,\n",
              " tensor([[[0.4181, 0.1296, 0.9465,  ..., 0.8124, 0.7553, 0.4182],\n",
              "          [0.5369, 0.8904, 0.1461,  ..., 0.0539, 0.7357, 0.6345],\n",
              "          [0.2825, 0.6645, 0.4535,  ..., 0.6589, 0.7332, 0.1003],\n",
              "          ...,\n",
              "          [0.2654, 0.6168, 0.8085,  ..., 0.6390, 0.1245, 0.1312],\n",
              "          [0.6854, 0.3788, 0.6756,  ..., 0.9613, 0.0683, 0.7830],\n",
              "          [0.8271, 0.4809, 0.7089,  ..., 0.8523, 0.2096, 0.8166]],\n",
              " \n",
              "         [[0.0122, 0.4580, 0.8222,  ..., 0.5274, 0.7653, 0.7973],\n",
              "          [0.6933, 0.6642, 0.4589,  ..., 0.9177, 0.1096, 0.6316],\n",
              "          [0.0382, 0.7760, 0.9565,  ..., 0.8751, 0.4291, 0.9947],\n",
              "          ...,\n",
              "          [0.1617, 0.9678, 0.0134,  ..., 0.2007, 0.8437, 0.8224],\n",
              "          [0.5739, 0.6729, 0.6740,  ..., 0.6910, 0.4664, 0.1171],\n",
              "          [0.7966, 0.0123, 0.5080,  ..., 0.2152, 0.4880, 0.6903]],\n",
              " \n",
              "         [[0.6106, 0.9827, 0.8729,  ..., 0.2030, 0.2387, 0.9509],\n",
              "          [0.9601, 0.9357, 0.5231,  ..., 0.5158, 0.5475, 0.0295],\n",
              "          [0.9480, 0.4338, 0.7145,  ..., 0.4317, 0.4843, 0.2287],\n",
              "          ...,\n",
              "          [0.2894, 0.7219, 0.7414,  ..., 0.0839, 0.7180, 0.3621],\n",
              "          [0.2485, 0.2265, 0.7823,  ..., 0.0299, 0.1315, 0.3646],\n",
              "          [0.7967, 0.9326, 0.4222,  ..., 0.6680, 0.4793, 0.4119]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zeros and ones\n"
      ],
      "metadata": {
        "id": "-Bt5O6BnYtYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zeros and ones --> Tensors with numbers 0 and 1s\n",
        "zeros_tensor = torch.zeros(size=(1, 3))\n",
        "zeros_tensor, zeros_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeptDnuUY0uF",
        "outputId": "c07fcbf5-e54b-410d-f785-b242c232b8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.]]), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones_tensor = torch.ones(size=(1,3))\n",
        "ones_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qf_yzCcY-W7",
        "outputId": "c2535cae-84c6-4a29-f2c7-c742222ce4f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a range and tensors like"
      ],
      "metadata": {
        "id": "du-Mr90JZgfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# range might be deprecated, so consider arange\n",
        "zero_to_one = torch.arange(start = 1, end = 11, step = 1)\n",
        "zero_to_one"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRjklj5iZhXi",
        "outputId": "5e44817d-ad09-4c1d-cadb-e1628ad75627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# like --> used to create a new tensor with same shape of another tensor...\n",
        "like_tensor1 =  torch.rand_like(input = zero_to_one, dtype=torch.float)\n",
        "like_tensor2 = torch.zeros_like(input = zero_to_one)\n",
        "like_tensor1, like_tensor2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi2G-FvPZxaQ",
        "outputId": "b7d32e33-4f6f-482c-e21e-943601267a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.4714, 0.4759, 0.8786, 0.6707, 0.5415, 0.1384, 0.4665, 0.3647, 0.4928,\n",
              "         0.3285]),\n",
              " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Data Types\n",
        "\n",
        "```Note: ``` Tensor Datatypes is one of the 3 big errors we will run into Pytorch and deep learning...<br>\n",
        "1. Tensors not the right Datatype<br>\n",
        "2. Tensors not the right shape<br>\n",
        "3. Tensors not the right device<br>"
      ],
      "metadata": {
        "id": "QqqBfNFqajtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default datatype for tensors is float32\n",
        "# The higher the precision value (8, 16, 32), the more detail and hence data used to express a number\n",
        "\n",
        "float_32_tensor = torch.rand([5,2], dtype=torch.float16)\n",
        "\n",
        "# General Format of tensor\n",
        "float_32_tensor  = torch.rand([5,2],\n",
        "                              dtype=None, #Dtype for tensor\n",
        "                              device=None, #What device is the tensor stored on? (usually GPU or CPU)\n",
        "                              requires_grad=False # if True, operations performed on the tensor are recorded(tracked)\n",
        "                              )\n",
        "#To convert dtype, syntax: i.e: a.type(torch.float16)\n",
        "float_32_tensor.dtype, float_32_tensor.shape, float_32_tensor, float_32_tensor.type(torch.float16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vG44f7NaGqHa",
        "outputId": "aafcb216-56ee-4b2a-9d1c-80247faf830a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32,\n",
              " torch.Size([5, 2]),\n",
              " tensor([[0.6058, 0.2868],\n",
              "         [0.4831, 0.3258],\n",
              "         [0.4199, 0.7753],\n",
              "         [0.6308, 0.3828],\n",
              "         [0.0795, 0.8305]]),\n",
              " tensor([[0.6060, 0.2869],\n",
              "         [0.4832, 0.3259],\n",
              "         [0.4199, 0.7754],\n",
              "         [0.6309, 0.3828],\n",
              "         [0.0795, 0.8306]], dtype=torch.float16))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Information from tensors`:\n",
        "\n",
        "`shape` - what shape is the tensor? (some operations require specific shape rules)<br>\n",
        "`dtype` - what datatype are the elements within the tensor stored in?<br>\n",
        "`device` - what device is the tensor stored on? (usually GPU or CPU)"
      ],
      "metadata": {
        "id": "3qZyGHyvHD7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_info = torch.rand([2,4], dtype=torch.float16) #(same as torch.half)\n",
        "tensor_info.dtype, tensor_info.shape, tensor_info.device #(Will Default to cpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1UhuUpbJCGZ",
        "outputId": "0a9e1d2a-bbc9-4713-96ac-d376a2d75d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float16, torch.Size([2, 4]), device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manipulating tensors (tensor operations)\n",
        "\n",
        "In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.\n",
        "\n",
        "These operations are often a wonderful dance between:\n",
        "\n",
        "Addition<br>\n",
        "Substraction<br>\n",
        "Multiplication (element-wise)<br>\n",
        "Division<br>\n",
        "Matrix multiplication<br>"
      ],
      "metadata": {
        "id": "WWsFCEyMK9mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic Operations:\n",
        "tensor_add = torch.ones(size=[5], dtype=torch.int32) #(also alias as int32 = int)\n",
        "tensor_add + 10\n",
        "\n",
        "tensor_sub = torch.zeros_like(input=tensor_add)\n",
        "tensor_sub - 10\n",
        "\n",
        "tensor_mul = torch.rand_like(input=tensor_sub, dtype=torch.float32)\n",
        "tensor_mul * 100 #Element Multiplication\n",
        "\n",
        "tensor_div = tensor_add / 10\n",
        "tensor_div\n",
        "\n",
        "#Built-in functions for operations\n",
        "tensor_func1 = torch.add(tensor_add , 10)\n",
        "tensor_func1\n",
        "\n",
        "tensor_func2 = torch.sub(tensor_func1, 1)\n",
        "tensor_func2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zKZKSg_lLeuW",
        "outputId": "8a431e12-422d-458d-e538-7c426c765542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 10, 10, 10, 10], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```Matrix multiplication```\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "PyTorch implements matrix multiplication functionality in the torch.matmul() or torch.mm() method.<br>\n",
        "\n",
        "**The main two rules for matrix multiplication to remember are:**\n",
        "\n",
        "**The inner dimensions must match:**<br>\n",
        "(3, 2) @ (3, 2) won't work<br>\n",
        "(2, 3) @ (3, 2) will work<br>\n",
        "(3, 2) @ (2, 3) will work<br><hr>\n",
        "\n",
        "**The resulting matrix has the shape of the outer dimensions:**<br>\n",
        "(2, 3) @ (3, 2) -> (2, 2)<br>\n",
        "(3, 2) @ (2, 3) -> (3, 3)"
      ],
      "metadata": {
        "id": "vzU03ulrMq0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([5,4,3])\n",
        "tensor\n",
        "torch.matmul(tensor, tensor) #Can also use the \"@\" symbol for matrix multiplication\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaliYDFwO7NP",
        "outputId": "b9a429b6-f7b2-4d67-83d8-5061f073d150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(50)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Matrix multi in hand\n",
        "total = 0\n",
        "for i in tensor:\n",
        "  total += i.item() * i.item()\n",
        "total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf4lkb_ZTHjK",
        "outputId": "1a532845-90cc-4fbb-cb0d-eb30997eef2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.64 ms, sys: 0 ns, total: 1.64 ms\n",
            "Wall time: 2.47 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor) #Function is faster..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJG9yXVeT2Jj",
        "outputId": "942ce55c-f83c-4da5-aeb6-0dbb14f412bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.41 ms, sys: 78 µs, total: 1.49 ms\n",
            "Wall time: 1.81 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(50)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "One of the most common errors in deep learning (shape errors)"
      ],
      "metadata": {
        "id": "IdxNp8prUHLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.rand(5,4)\n",
        "tensor2 = torch.rand(6,4)\n",
        "torch.matmul(tensor1, tensor2) #Can be solved by Transpose..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "NkLwcIhhUN66",
        "outputId": "fb0a83ba-968d-4e83-869f-d840a8bcae6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (5x4 and 6x4)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-4ed5d3edeb65>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtensor1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtensor2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Can be solved by Transpose...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (5x4 and 6x4)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape of T1 is (5, 4)\\nShape of T2 is (6,4)\\nShape of T2 tranpose is (4,6)')"
      ],
      "metadata": {
        "id": "km-uMCsDUcU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eg Of Transpose\n",
        "# torch.transpose(input, dim0, dim1) - where input is the desired tensor to transpose and dim0 and dim1 are the dimensions to be swapped.\n",
        "# tensor.T - where tensor is the desired tensor to transpose\n",
        "\n",
        "tensor2.T, tensor2.T.shape"
      ],
      "metadata": {
        "id": "XnY6ULhWVDL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Aggregation"
      ],
      "metadata": {
        "id": "2oYqS3FQ3pWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the Min, Max, Mean, Sum of Tensor\n",
        "# Either we can use Aggregator function torch.method(tensor) or method in tensor [i.e a.min()]\n",
        "\n",
        "import torch\n",
        "a = torch.arange(1,11)\n",
        "b = torch.rand([5,2])\n",
        "#Min\n",
        "a.min(), torch.min(a)\n",
        "\n",
        "#Max\n",
        "a.max(), torch.max(a)\n",
        "\n",
        "#Mean\n",
        "mean_a = a.type(torch.float32).mean() #As mean involved float, we need to change data type as needed...\n",
        "mean_a\n",
        "\n",
        "#Sum\n",
        "sum_a = a.sum() #sum all the value in tensors\n",
        "sum_b = b.sum()\n",
        "sum_b, sum_b.type(), mean_a"
      ],
      "metadata": {
        "id": "DA2wvcoF3vG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positional min/max**\n",
        "\n",
        "You can also find the index of a tensor where the max or minimum occurs with torch.argmax() and torch.argmin() respectively."
      ],
      "metadata": {
        "id": "2euVVTauIkm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argmax(a), torch.argmin(a)\n",
        "\n",
        "print(f\"Index where max value occurs: {a.argmax()}\")\n",
        "print(f\"Index where min value occurs: {a.argmin()}\")"
      ],
      "metadata": {
        "id": "QPiwe-GyIoe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reshaping, viewing and stacking\n",
        "\n",
        "Often times you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ARBcPQT44i38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Popular methods are:**\n",
        "\n",
        "* Reshaping -  reshapes an input tensor to defined shape.\n",
        "* View - Return a view of input tensor of certain shape, but keep the same memory(value) as the original tensor.\n",
        "* Stacking - Combines multiple tensor each other on top (vstack) or side by side (hstack)\n",
        "* Squeeze - Removes a all `1` dimension from a tensor.\n",
        "* Unsqueeze - Add a `1` dimension to a target tensor.\n",
        "* Permute - Return a view of the input with dimensions permuted (swapped) in a certain way.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vmwiwgSD6LXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "#Reshaping..\n",
        "x = torch.tensor([10, 9, 8, 7, 5, 4, 5, 6,7,10])\n",
        "print(x)\n",
        "print(x.reshape(2,5))\n",
        "\n",
        "# Also use as torch.reshape(input, dim)\n",
        "x_reshaped = torch.reshape(x, (5,2))\n",
        "print(x_reshaped.reshape(-1)) # -1 redefines shape as single dim...\n",
        "\n",
        "#View\n",
        "print('\\nView')\n",
        "v = x.view(5,2)\n",
        "print(v) #View doesn't change shape of original tensor, they only do change values of original tensor...\n",
        "print(x)\n",
        "\n",
        "# If Value of v changes, then x(original) also changes..\n",
        "v[:][0] = 1999 #(View of tensor shares the memory as original tensor...)\n",
        "print(v)\n",
        "print(x)\n",
        "\n",
        "#Stacking\n",
        "#Dim = 0 (vstack), dim = 1 (hstack)\n",
        "s = torch.stack((x, x, x, x), dim=1)\n",
        "print(s)\n",
        "\n",
        "#Squeeze\n",
        "print(\"\\nSqueeze\")\n",
        "y = torch.rand(1,5,1)\n",
        "print(y)\n",
        "print(y.shape)\n",
        "y_squeezed = y.squeeze()\n",
        "print(y_squeezed.shape)\n",
        "print(y_squeezed)\n",
        "\n",
        "#Unsqueeze\n",
        "print('\\nunsqueeze')\n",
        "y_unsqueezed = y_squeezed.unsqueeze(dim=0)\n",
        "print(y_unsqueezed)\n",
        "print(y_unsqueezed.shape)\n",
        "\n",
        "#Permute\n",
        "# Eg: Swapping of color channel of view...\n",
        "print('\\npermute\\n')\n",
        "image_encode = torch.rand(224,224,3) #-> [height, width, color]\n",
        "print(f'Before Permute: {image_encode.shape}')\n",
        "permuted_img = image_encode.permute(dims=(2,0,1)) # [color, height, width]\n",
        "print(f'After Permute: {permuted_img.shape}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "glOIugXxvwHC",
        "outputId": "d43b3861-71a2-46f1-9b73-6c1091732912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10,  9,  8,  7,  5,  4,  5,  6,  7, 10])\n",
            "tensor([[10,  9,  8,  7,  5],\n",
            "        [ 4,  5,  6,  7, 10]])\n",
            "tensor([10,  9,  8,  7,  5,  4,  5,  6,  7, 10])\n",
            "\n",
            "View\n",
            "tensor([[10,  9],\n",
            "        [ 8,  7],\n",
            "        [ 5,  4],\n",
            "        [ 5,  6],\n",
            "        [ 7, 10]])\n",
            "tensor([10,  9,  8,  7,  5,  4,  5,  6,  7, 10])\n",
            "tensor([[1999, 1999],\n",
            "        [   8,    7],\n",
            "        [   5,    4],\n",
            "        [   5,    6],\n",
            "        [   7,   10]])\n",
            "tensor([1999, 1999,    8,    7,    5,    4,    5,    6,    7,   10])\n",
            "tensor([[1999, 1999, 1999, 1999],\n",
            "        [1999, 1999, 1999, 1999],\n",
            "        [   8,    8,    8,    8],\n",
            "        [   7,    7,    7,    7],\n",
            "        [   5,    5,    5,    5],\n",
            "        [   4,    4,    4,    4],\n",
            "        [   5,    5,    5,    5],\n",
            "        [   6,    6,    6,    6],\n",
            "        [   7,    7,    7,    7],\n",
            "        [  10,   10,   10,   10]])\n",
            "\n",
            "Squeeze\n",
            "tensor([[[0.4253],\n",
            "         [0.6988],\n",
            "         [0.2795],\n",
            "         [0.5995],\n",
            "         [0.8625]]])\n",
            "torch.Size([1, 5, 1])\n",
            "torch.Size([5])\n",
            "tensor([0.4253, 0.6988, 0.2795, 0.5995, 0.8625])\n",
            "\n",
            "unsqueeze\n",
            "tensor([[0.4253, 0.6988, 0.2795, 0.5995, 0.8625]])\n",
            "torch.Size([1, 5])\n",
            "\n",
            "permute\n",
            "\n",
            "Before Permute: torch.Size([224, 224, 3])\n",
            "After Permute: torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Indexing"
      ],
      "metadata": {
        "id": "YSDPkVv5xS2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = torch.rand(2,5, 5)\n",
        "print(d)\n",
        "# use ':' to select all dimension of target tensor..\n",
        "d[:,0,:]\n",
        "\n",
        "k = torch.arange(1,10).reshape(3,3)\n",
        "print(k)\n",
        "k[:,2]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9u7LBsCQ5Ci",
        "outputId": "b86129e6-2ee3-437d-ee95-f714d9b6d53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.2727, 0.1165, 0.2907, 0.8362, 0.5557],\n",
            "         [0.6981, 0.0427, 0.8799, 0.3198, 0.2318],\n",
            "         [0.3750, 0.4334, 0.5570, 0.5143, 0.1944],\n",
            "         [0.9629, 0.9516, 0.9488, 0.2245, 0.9496],\n",
            "         [0.0487, 0.5701, 0.8088, 0.0272, 0.7508]],\n",
            "\n",
            "        [[0.4626, 0.8885, 0.2106, 0.6444, 0.6154],\n",
            "         [0.4031, 0.2941, 0.7376, 0.9125, 0.5605],\n",
            "         [0.6960, 0.0202, 0.1828, 0.0382, 0.1327],\n",
            "         [0.6646, 0.2006, 0.1599, 0.9340, 0.7502],\n",
            "         [0.7035, 0.7754, 0.4672, 0.4264, 0.0338]]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 6, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pytorch and NumPy\n",
        "\n",
        "NumPy is a popular Python numerical computing library, PyTorch has functionality to interact with it nicely.\n",
        "\n",
        "The two main methods you'll want to use for NumPy to PyTorch (and back again) are:\n",
        "\n",
        "1. torch.from_numpy(ndarray) - NumPy array -> PyTorch tensor.<br>\n",
        "2. torch.Tensor.numpy() - PyTorch tensor -> NumPy array."
      ],
      "metadata": {
        "id": "y6GQzCb_1cr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Numpy Array to tensor.\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "array = np.arange(1.0,11.0) #np default type is float64\n",
        "print(array, array.dtype, '\\n')\n",
        "\n",
        "#To convert np array into tensor.\n",
        "nparray_to_tensor = torch.from_numpy(array)\n",
        "print(nparray_to_tensor, '\\n') # Final conversion is in form of original dtype\n",
        "\n",
        "#Changing the value affect the another compatible tenspr and vice-versa...(shares same memory)\n",
        "nparray_to_tensor[0] = 11\n",
        "array + 1\n",
        "print(array, nparray_to_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyI9J9Tt4ahO",
        "outputId": "ebf90448-8c45-46bc-eac3-d08b8b248d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.] float64 \n",
            "\n",
            "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], dtype=torch.float64) \n",
            "\n",
            "[11.  2.  3.  4.  5.  6.  7.  8.  9. 10.] tensor([11.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor to NumPy Array\n",
        "tensor_py = torch.arange(1.0,10.0)\n",
        "print(tensor, tensor.dtype, '\\n') #tensor default type is float32\n",
        "\n",
        "#To convert tensor to numpy array\n",
        "tensor_to_array = tensor_py.numpy()\n",
        "print(tensor_to_array, '\\n') # Final conversion is in form of original dtype\n",
        "\n",
        "#Changing the value also affect another...\n",
        "tensor_to_array[0] = 10\n",
        "print(tensor_to_array, tensor_py)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tuu6UobT4eXF",
        "outputId": "fd155033-dd52-47b4-ca65-689b21acc62c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]) torch.float32 \n",
            "\n",
            "[1. 2. 3. 4. 5. 6. 7. 8. 9.] \n",
            "\n",
            "[10.  2.  3.  4.  5.  6.  7.  8.  9.] tensor([10.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reproducibility (trying to take the random out of random)\n",
        "\n",
        "How neutral network learns?\n",
        "\n",
        "* start with random numbers -> tensor operations -> try to make better (again and again and again)\n",
        "\n",
        "To reduce the randomness in tensor, we need to use concepts of **Random seed**<br>\n",
        "**Random seed** \"flavour\" the randomness"
      ],
      "metadata": {
        "id": "fHsrnFqh7600"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "#Create the 2 random tensor\n",
        "rand_tensor_A = torch.rand(3,3)\n",
        "rand_tensor_B = torch.rand(3,3)\n",
        "print(rand_tensor_A, '\\n', rand_tensor_B)\n",
        "print(rand_tensor_A == rand_tensor_B)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wA6-P8nBgDh",
        "outputId": "67190836-db8a-404d-a7e3-2018f8fcdd8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4798, 0.7496, 0.2418],\n",
            "        [0.0642, 0.8823, 0.5980],\n",
            "        [0.8143, 0.7880, 0.7144]]) \n",
            " tensor([[0.3939, 0.8319, 0.3079],\n",
            "        [0.0439, 0.1751, 0.6132],\n",
            "        [0.3634, 0.8089, 0.9987]])\n",
            "tensor([[False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To solve the issue use resproducible tensor\n",
        "\n",
        "#set the random seed.\n",
        "RANDOM_SEED = 42 #(flavour)This sets a specific seed for PyTorch's random number generator\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "rand_tensor_C = torch.rand(3,3) # function ensures that the sequence of random numbers is always the same every time you set this seed, making tensor generation predictable.\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "rand_tensor_D = torch.rand(3,3)\n",
        "\n",
        "print(rand_tensor_C, '\\n', rand_tensor_D)\n",
        "print(rand_tensor_C == rand_tensor_D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf3ppbmNDimt",
        "outputId": "27f4c355-20f8-4e13-cd10-a257f6bb9f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829],\n",
            "        [0.9593, 0.3904, 0.6009],\n",
            "        [0.2566, 0.7936, 0.9408]]) \n",
            " tensor([[0.8823, 0.9150, 0.3829],\n",
            "        [0.9593, 0.3904, 0.6009],\n",
            "        [0.2566, 0.7936, 0.9408]])\n",
            "tensor([[True, True, True],\n",
            "        [True, True, True],\n",
            "        [True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Running tensors on GPUs (and making faster computations)\n",
        "\n",
        "How to get?\n",
        "* Google Colabs\n",
        "* Use your own(Run everything locally on your own machine)\n",
        "* Cloud computing (AWS, GCP, Azure)"
      ],
      "metadata": {
        "id": "1u41c6aIFe2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To check if you've got access to a Nvidia GPU, you can run !nvidia-smi.\n",
        "#running pytorch and tensors on gpu, make computations faster..\n",
        "\n",
        "# GPU = Thanks to CUDA + nividia(hardware) + Pytorch(working behind the scenes)\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "MeysZMP2FjI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb3b71dc-cfc8-4a09-c1af-367e3c452cd3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Sep  7 06:11:43 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU access with Pytorch\n",
        "import torch\n",
        "torch.cuda.is_available()\n",
        "\n",
        "#setting up device agnostic code..\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device, '\\n')\n",
        "\n",
        "#Count the number of gpu\n",
        "print(torch.cuda.device_count(), '\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn0SZZ2rHjb_",
        "outputId": "3da152a3-edb8-4c2e-f2c9-0b7d17a405f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda \n",
            "\n",
            "1 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting the tensor and Models on GPU\n",
        "\n",
        "tensor = torch.tensor([1,2,3,4,5], device='cuda')\n",
        "print(tensor, '\\n', tensor.device)\n",
        "\n",
        "#moving tensor to gpu (if available)\n",
        "tensor1 = torch.tensor([1,2,34,5,6])\n",
        "tensor_on_gpu = tensor1.to(device) #by using to method we can move tensor on diff devices...\n",
        "print(tensor_on_gpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YepPT12gKG8n",
        "outputId": "132f23b6-3519-4ad1-b1f7-9cccdbc2a9c2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5], device='cuda:0') \n",
            " cuda:0\n",
            "tensor([ 1,  2, 34,  5,  6], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Moving back tensor on CPU\n",
        "\n",
        "#Note: Numpy not work on GPU\n",
        "tensor_on_gpu.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "wu6wnqQDL347",
        "outputId": "fd25beb1-e62f-4e0c-c4b8-af0c7ed46688"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-57a810344516>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Note: Numpy not work on GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtensor_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To fix issue we need to first set it to CPU\n",
        "tensor_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_on_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tddSDW-wME38",
        "outputId": "8660e4e9-4d78-407c-c629-81cac6c05ba8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  2, 34,  5,  6])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(1,7)\n",
        "b = torch.rand(1,7)\n",
        "\n",
        "torch.matmul(a, b.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-lvWODuN2dt",
        "outputId": "7a8767e8-4897-4b26-b9a1-b43467d6f465"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.9341]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}